---
title: æ“ä½œç³»ç»ŸåŸç†æ€»ç»“
date: 2019-04-12 23:03:06
cover: https://raw.githubusercontent.com/HanyuuFurude/TechBlog/master/res/rm.png
tags: 
	- os
	- review
categories: review
---
[TOC]

# Chapter 1 Introduction

* System view
	* Resource allocator
	* Control program

* Dual-Mode Operation
	* User mode
	* Kernel mode
		*   privileged instruction
		*   ![](/Review/OS/1555051141346.png)
		*   ![](/OS/1555051141346.png)
	* Hardware
	* **CPU protection**
		*   **timer**
		    *   **time sharing**
	* **memory protection**
		*   **Base register**
		*   **Limit register**
	* **I/O protection**
		*   **all I/O instruction are privilege instructions**

* Development of OS
	*   mainframe systems

		*   NO OS
		*   **batch systems**
		*   **multiprogramming systems**
		*   **time sharing systems**

	*   desktop systems

	*   multiprocessor systems

	*   distributed systems

	*   clustered systems

	*   real-time systems

	*   handheld systems

	*   ç°ä»£æ“ä½œç³»ç»Ÿçš„ç‰¹å¾

		*   **å¹¶å‘æ€§Concurrence**
		*   **å…±äº«æ€§Sharing**
		*   **è™šæ‹Ÿæ€§Virtual**
		*   **å¼‚æ­¥æ€§Asynchronism**
		*   æé«˜CPUåˆ©ç”¨ç‡ï¼Œå……åˆ†å‘æŒ¥å¹¶å‘æ€§ï¼š**ç¨‹åºä¹‹é—´ã€è®¾å¤‡ä¹‹é—´ã€è®¾å¤‡ä¸CPUä¹‹é—´**å‡**å¹¶å‘**

	*   Prï¼š

		æ‰¹å¤„ç†ç³»ç»Ÿã€å¤šé“ç¨‹åºç³»ç»Ÿå’Œåˆ†æ—¶ç³»ç»Ÿçš„æŠ€æœ¯ç‰¹æ€§

# Chapter 2 Operating-System Structures

*   åŠŸèƒ½å’ŒæœåŠ¡çš„å·®åˆ«ï¼š
    *   å¯¹å†…ï¼šè‡ªè¡Œå®ç°
    *   å¯¹å¤–ï¼šå¯ä»¥è°ƒç”¨å…¶ä»–åŠŸèƒ½ä»£ä¸ºå®ç°
*   common function of OS
    *   process management
        *   process synchronization
        *   process communication
        *   deadlock handling
        *   (åˆ†å¸ƒå¼)
    *   main memory management
    *   secondary-storage management
    *   file management
    *   I/O system management
*   Operating System Services(Services for **helping users**)
    *   Program execution
    *   I/O operations
    *   File-system manipulation
    *   Communications
    *   Error detection
    *   Resource allocation
    *   Accounting(å®¡è®¡)
    *   Protection
*   Operating System Interface
    *   Interface to programs
        *   **System calls**
            *   System-call interface(SCI)
            *   Application Programming Interface(API)
                *   managed by runtime support library
        *   ![](/Review/OS/1555145491705.png)
        *   ![](/OS/1555145491705.png)
            *   Types of System calls
                *   Process control
                *   File management
                *   Device management
                *   Information maintenance
                *   Communications
    *   **PR. Why do user use APIs rather than system calls directory?**
    *   **ANS.**
        1.  è·¨å¹³å°èƒ½åŠ›ï¼ˆæä¾›ç›¸åŒçš„APIå°è£…ï¼‰ç§»æ¤æ€§å¥½
        2.  æ¨¡å—åŒ–å°è£…ï¼Œå¯ç»´æŠ¤æ€§å¥½
        3.  ç®€åŒ–äº†ç¨‹åºç¼–å†™
        4.  æé«˜äº†æ‰§è¡Œæ•ˆç‡
*   Operating System Structure
    *   Simple structure
    *   Layered structure
        *   virtual machines
    *   Microkernel structure
        *   Benefis
            *   easier to extend
            *   easier to port
            *   more reliable
            *   more secure
    *   Modules
    *   PR:è®¾è®¡æ“ä½œç³»ç»Ÿæ—¶é‡‡ç”¨çš„æ¨¡å—åŒ–å†…æ ¸æ–¹æ³•å’Œåˆ†å±‚æ–¹æ³•åœ¨é‚£äº›æ–¹é¢ç±»ä¼¼ï¼Ÿé‚£äº›æ–¹é¢ä¸åŒï¼Ÿ
*   Operating system design and implementation
*   å°ç»“
    *   æ“ä½œç³»ç»Ÿæ¦‚å¿µï¼ˆç®¡ç†èµ„æºã€æ”¯æŒç¨‹åºè¿è¡Œã€æ–¹ä¾¿ç”¨æˆ·ä½¿ç”¨çš„**ç¨‹åºé›†**ï¼‰
    *   æ“ä½œç³»ç»Ÿçš„åŸºæœ¬ç›®æ ‡ï¼š**æ–¹ä¾¿æ€§å’Œé«˜æ•ˆæ€§**
    *   å¼•å¯¼ç¨‹åºï¼š**ä¸­æ–­ã€ä¸­æ–­å¤„ç†ç¨‹åºã€ä¸­æ–­å‘é‡**
    *   å‚¨å­˜ç»“æ„ï¼šå†…å­˜ï¼ˆ**å°ã€æ˜“å¤±**ï¼‰äºŒçº§å‚¨å­˜ï¼ˆ**å¤§ã€éæ˜“å¤±**ï¼‰ã€åˆ†å±‚ç»“æ„
    *   I/Oç»“æ„ï¼šè®¾å¤‡æ§åˆ¶å™¨ï¼ˆæœ¬åœ°ç¼“å†²ï¼‰ã€DMA
    *   ç¡¬ä»¶ä¿æŠ¤ï¼š**åŒé‡æ¨¡å¼æ“ä½œã€ç‰¹æƒæŒ‡ä»¤ã€I/Oä¿æŠ¤ã€å†…å­˜ä¿æŠ¤ã€CPUä¿æŠ¤**
    *   æ“ä½œç³»ç»Ÿçš„å‘å±•ï¼še.g: å¤šé“ç¨‹åºè®¾è®¡
    *   æ“ä½œç³»ç»Ÿçš„åŠŸèƒ½ï¼šè¿›ç¨‹ï¼ˆCPUï¼‰ç®¡ç†ã€å†…å­˜ç®¡ç†ã€ç£ç›˜ç®¡ç†ã€æ–‡ä»¶ç®¡ç†ã€I/Oç®¡ç†ã€**ç”¨æˆ·æ¥å£**
    *   æ“ä½œç³»ç»ŸæœåŠ¡ï¼š**ç¨‹åºæ‰§è¡Œã€I/Oæ“ä½œã€æ–‡ä»¶ç³»ç»Ÿæ“ä½œã€é€šä¿¡ã€é”™è¯¯æ£€æµ‹ä¸å¤„ç†**ã€èµ„æºåˆ†é…ã€ç»Ÿè®¡ã€ä¿æŠ¤
    *   æ“ä½œç³»ç»Ÿæ¥å£ï¼šç”¨æˆ·æ¥å£ï¼ˆCLIã€GUIï¼‰ã€ç¨‹åºæ¥å£ï¼ˆ**ç³»ç»Ÿè°ƒç”¨ï¼ˆå‚æ•°ä¼ é€’ã€ç±»å‹ï¼‰**ï¼‰ã€SCIã€API
    *   æ“ä½œç³»ç»Ÿç»“æ„

# Chapter 3 Process

*   Process 

	*   test section(program code)
	*   **program counter**
	*   **contents of the processer's registers**
	*   Heap-stack
	*   data section
	*   ![](/Review/OS/1555171608763.png)
	*   ![](OS/1555171608763.png)
	*   **Characteristic of process**
	    *   **DynamicåŠ¨æ€æ€§**
	    *   **Independencyç‹¬ç«‹æ€§**
	    *   **Concurrenceå¹¶å‘æ€§**
	    *   **Structureç»“æ„åŒ–**
	*   PR.è¿›ç¨‹å’Œç¨‹åºæ˜¯ä¸¤ä¸ªå¯†åˆ‡ç›¸å…³çš„æ¦‚å¿µï¼Œè¯·é˜è¿°ä»–ä»¬ä¹‹é—´çš„åŒºåˆ«å’Œè”ç³»
	*   Process state
	*   ![](/Review/OS/1555173365887.png)
	*   ![](OS/1555173365887.png)
	*   Process control block(PCB)
	*   ![](/Review/OS/1555173537094.png)
	*   ![](OS/1555173537094.png)

*   Process scheduling queues

	*   Job queue (in main memory)
	    *   Ready queue 
	    *   device queues
	        *   process migration between the various queues
	        *   ![](/Review/OS/1555217568804.png)
	        *   ![](OS/1555217568804.png)
	        *   ![](/Review/OS/1555217608602.png)
	        *   ![](OS/1555217608602.png)
	    *   Schedulers
	        *   Long-term scheduler(ç§’çº§ã€åˆ†é’Ÿçº§ï¼Œä½œä¸šè°ƒåº¦)
	        *   Short-term scheduler(æ¯«ç§’çº§ï¼ŒCPUè°ƒåº¦)
	        *   Medium-term scheduler(swapping)
	    *   I/O bound process
	    *   CPU bound process
	    *   Context switch
	        *   The **context** of a process is represented in **PCB** of the process and includes the values of CPU registers.
	        *   ä¿å­˜æ‰§è¡Œåçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
	        *   ä¸Šä¸‹æ–‡åˆ‡æ¢ä¼šå¸¦æ¥å¼€é”€
	        *   å°½é‡å‡å°‘ä¸Šä¸‹æ–‡åˆ‡æ¢ä»¥å‡å°‘å¼€é”€
	        *   ![](/Review/OS/1555685657476.png)
	        *   ![](OS/1555685657476.png)

*   Operation on Process

	*   Process creation

		*   child process(unique process identifier(int)), tree of process

		*   resource sharing

			*   parent and children shall all resources
			*   children share subset of parentâ€™s resources
			*   parent and child share no resources

		*   Execution

			*   Parent and children execute concurrently
			*   Parent waits until children terminate

		*   Address space

			*   child duplicate of parent

			*   child has a program loaded into it (new text section)

			*   UNIX examples

				*   fork() :create new process

				*   exec() :used after a fork to replace the processâ€™s memory space with a new program

					![](/review/OS/1555737064290.png)

				*   ![](OS/1555737064290.png)

				*   ``` c++
					pid = fork();
					if(pid<0)	/* error occured */
					{
					    printf(stderr,"Fork failed");
					    exit(-1);
					}
					else if(pid==0)	/* child process */
					{
					    execlp("/bin/ls","ls",NULL);
					}
					else	/* parent process */
					{
					    wait(NULL);	/* wait for child process to finish */
					    printf("Child complete");
					    exit(0);
					}
					```

			*   Process Termination

				*   exit()  process executes last statement and asks the operating system to delete it
				    *   output data from child to parent (via wait)
				    *   Processâ€™s resources are deallocated by OS
				*   abort()  parent may terminate execution of children process
				    *   child has exceeded allocated resources
				    *   task assigned to child is no longer required
				    *   parent is exiting <small>^*^not all of the operation system supports **Cascading termination(çº§è”ç»ˆæ­¢)**</small>

*   InterProcess Communication(**IPC**)

	*   **Independent** process cannot affect or be effected by the execution of another process

	*   **Cooperating** process can affect or be effected by the execution of another process

		*   Advantages

			1. Information sharing

			2. Computation speed-up

			3. Modularity

			4. Convenience

	*   **Shared memory** & **Message passing**

		![](/review/OS/1555742278383.png)

		![](OS/1555742278383.png)

		- Shared-memory Systems

			- requiring communication process to establish a region of shared memory
			- a shared memory region resides in the address space of the process creating the shared memory segment
			- the processes are responsible for ensuring that they are not writing to the **same location simultaneously**
				- Producer-Consumer Problem

		- Message-passing Systems

			- MPS has two operations

				- send()
				- receive()

			- communication link

				1. link may be unidirectional or bidirectional 

				2. a link may be associated with many processes

				- direct communication

					- send(P,message) send a message to process P
					- receive(Q,message)  receive a message from process Q

				- indirect communiction

					- mailboxes

						- each mailbox has a unique id

						- two processes can communicate only if the share a mailbox

						- Operations

							> 1. create a new mailbox
							> 2. send and receive messages through mailbox
							> 3. destroy a mail box

		- Synchronization

			- Blocking: synchronous
			- Non-blocking: asynchronous

		- Buffering

			- **Zero capacity** sender must wait for receiver
			- **Bounded capacity** finite length of $n$ messages, sender must wait if link full
			- **Unbounded capacity** infinite length, sender never blocks

*   Communication in Client-Server System

	*   **Sockets**
	*   **Remote Procedure Calls**
	*   **Remote Method Invocation (Java)**

# Chapter 4 Threads

- Multithreading Models

  - A thread is a flow of control within a process

  - thread is a **basic** unit of CPU execution (known as LightWeight Process(LWP))

  - process (HeavyWeight process(HWP)) has a **single** thread of control

  - multithreaded process contains several **different** flows of control within the **same** address space

  - Thread

    - has

      - thread ID
      - program counter
      - register set
      - stack

    - share

      - code section

      - data section

      - other OS resources(file and signals)

      	![](/review/OS/1555762382921.png)

      	![](OS/1555762382921.png)

      - Benefits

      	- responsiveness
      	- resource sharing
      	- economy(low cost in overhead of creating and context-switch)
      	- Utilization of multiprocessor architectures

    - User Threads

      - user threads are supported above the kernel. The kernel is **not** aware of user threads

      - Library provides all support for thread creation, termination, joining and scheduling

      - more efficient(no kernel intervention)

      - if one thread is blocked, every other threads of the same process are also blocked(containing process is blocked)

        ![](/review/OS/1555764073008.png)

        ![](OS/1555764073008.png)

      - Kernel Threads

        - kernel threads are usually **slower** than the user threads

        - blocking one thread will **not** cause other threads of the same process to block

        - the kernel can schedule threads on different processors(in a multiprocessor environment)

          ![](/review/OS/1555764320920.png)

          ![](OS/1555764320920.png)

          **Pr.**

          1. è¿›ç¨‹å’Œçº¿ç¨‹ä¹‹é—´çš„åŒºåˆ«å’Œè”ç³»
          2. ç”¨æˆ·çº§çº¿ç¨‹å’Œå†…æ ¸çº§çº¿ç¨‹çš„åŒºåˆ«

    - Multithreading models

        - many to one 

            - only one thread in the one process can access the kernel at a time
            - true concurrency is not gained

            ![](/review/OS/1555767057845.png)

            ![](OS/1555767057845.png)

        - one to one

            - each user-level thread maps to kernel thread

            - providing more concurrency

            - restricting the number of threads supported by the system

                ![](/review/OS/1555767300046.png)

                ![](OS/1555767300046.png)

        - many to many

            - allow many user level threads to be mapped to many kernel threads

                ![](/review/OS/1555767517744.png)

                ![](OS/1555767517744.png)

- Thread Libraries

  - status
  - 

  ``` C++
  int pthread_create(tid,attr,function,arg);
  /*
   * pthread_t *tid
   	handle of created thread
   * const pthread_attr_t *attr
   	attribes of thread to be created
   * void *(*function)(void)
   	function to be mapped to thread
   * void * arg
   	single argument to function
   */
  int pthread_join(tid,val_ptr);
  /*
   * pthread_t *tid
   	handle of joinable thread
   * void ** var_ptr
   	exit value rturn by joined thread
   */
  void pthread_exit(void *status);
  int pthread_cancel(pthread_t thread);	//terminated immediately
  int pthread_kill(pthread_t thread,int sig);
  ```

  - CreateThread
  - GetCurrentThreadId
  - GetCurrentThread
  - SuspendThread/ResumeTread
  - ExitThread
  - TerminateThread
  - GetExitCodeThread
  - GetThreadTimes

- Threading Issues

- Operating System Examples

- //TODO å…³äºçº¿ç¨‹çš„å®ç°

- **Pr.**

  - ä¿¡å·æœºåˆ¶å’Œä¸­æ–­æœºåˆ¶çš„å¼‚åŒ

- Thread Pools

  - advantages
  	- faster to service a request(save the time to create new thread)
  	- allow the number of threads in the application to be bound to the size of the pool

- Thread specific data

  - threads belonging to a process share the data of the process
  - allows each thread to have its own copy of data
  - when using a thread pool, each thread may be assigned a unique identifier

- Scheduler activations

- **upcalls**

# Chapter 5 CPU Scheduling

*   Maximum CPU utilization obtained with multiprogramming

*   The success of CPU scheduling depends on an property of processes:**CPU-I/O Burst Cycle**

    *   process execution consists of a **cycle** of CPU execution and I/O wait.

*   CPU-bound

    *   a few very long CPU bursts

*   I/O-bound

    *   many short CPU bursts

    ![](/review/OS/1555849707110.png)

    ![](OS/1555849707110.png)

*   When the CPU is idle, the OS must select another ready process to run

*   This selection process is carried out by the **short-term scheduler**

*   The CPU scheduler selects a process from **the ready queue** and allocates the CPU to it

*   There are many ways to organize the ready queue<small>(e.g. FIFO)</small>

    ![](/review/OS/1555850618923.png)

    ![](OS/1555850618923.png)

*   Circumstances that scheduling may take place

    *   A process switches from the running state to the terminated state(finished)

    *   A process switches from the running state to the wait state(e.g. IO operation)

        â†‘ä¸»åŠ¨æ“ä½œâ†‘ éæŠ¢å å¼è°ƒåº¦

        ---

        â†“è¢«åŠ¨ä¸­æ­¢â†“ æŠ¢å å¼è°ƒåº¦ â†’ åŒæ­¥æœºåˆ¶

    *   A process switched from the running state to the ready state(e.g. a interrupt occurs)

    *   A process switches from the wait state to the ready state(e.g. I/O completion)

    *   A process switches from the new state to ready state(e.g. a higher priority process ready)

    *   Preemptive(æŠ¢å å¼)

        *   cost associated with access to **shared data**
        *   When the kernel is in its **critical** section modifying some important data .
        *   special attention to situation 

    *   Non-preemptive

        *   scheduling occurs when a process **voluntarily terminates**(ä¸»åŠ¨ç»“æŸ) (case1)or enters the wait state(case2)
        *   simple but very inefficient

    **Pr.**

    â€‹	å¯¹äºè®¡ç®—ä¸­å¿ƒï¼ŒæŠ¢å å¼è°ƒåº¦å’ŒéæŠ¢å å¼è°ƒåº¦å“ªä¸€ç§æ¯”è¾ƒé€‚åˆ

    -   Dispatcher(è°ƒåº¦) module
        -   switching context
        -   switching to user mode
        -   jumping to the proper location in the user program to restart that program
    -   Dispatch latency
        -   the dispatcher should be as fast as possible

*   Scheduling criteria

    *   CPU utilization

        *   keep the CPU as busy as possible
        *   lightly|40%|-|90%|heavily

    *   Throughput(åå)

        *   higher throughput means more jobs get done

        <small>ååé‡å’ŒCPUåˆ©ç”¨ç‡æœ‰ç›¸å…³æ€§ä½†å¹¶æ²¡æœ‰ç›´æ¥å…³ç³»</small>

    *   Turnaround time

        *   The time period from job submission to completion is the turnaround time

        $$t_{turnaround}=\\t_{waitingTimeBeforeEnteringTheSystem}+\\ t_{waitingTImeInTheReadyQueue}+\\t_{waitingTImeInAllOtherEvents}+\\t_{timeTheProcessActuallyRunningOnTheCPU}$$

*   Waiting time

    *   time in ready queue

*   Response time

    *   the time form the submission of a request

*   Optimization Criteria

    *   MAX CPU utilization
    *   MAX throughtput
    *   MIN turnaround time(average)
    *   MIN waiting time
    *   MIN response time

*    ä¸ºä»€ä¹ˆéœ€è¦CPUè°ƒåº¦

    å¤§å¤šæ•°ä»»åŠ¡æ˜¯CPUå’ŒI/Oäº¤æ›¿ä½¿ç”¨ï¼Œ

    å¯¼è‡´CPUå’ŒI/Oè‡³å°‘æœ‰ä¸€ä¸ªç©ºé—²ï¼Œ

    é€šè¿‡è°ƒåº¦è®©éœ€è¦æ‰§è¡ŒI/Oçš„ä»»åŠ¡å»æ‰§è¡ŒI/Oã€‚

    æŠŠCPUç»™éœ€è¦CPUçš„ä»»åŠ¡è¿è¡Œã€‚

*   **Scheduling Algorithms**

    *   First-Come-First-Served Scheduling (FCFS)
        *   can easily implemented using a queue
        *   not preemptive
        *   convoy effect (æŠ¤èˆªæ•ˆåº”)
        *   troublesome for time-sharing systems

    *   Short-Job-First Scheduling (SJF)

        *   sorted in next CPU burst length
        *   can be nonpreemptive and preemptive
        *   **minimum average waiting time for a given set of process**
        *   predict CPU burst: exponential averaging
        *   long jobs may meet **starvation**!!!

    *   Priority Scheduling
        *   each process has a **priority**

        *   priority may be determined internally or externally
            *   internal priority
                *   time limits
                *   memory requirement
                *   number of files
                *   etc.
            *   external priority
                *   importance of the process (not controlled by the OS)

        *   starvation/Indefinite block

            a lower priority may never have a chance to run

            *   Aging
                *   gradually increase the priority of process what wait in the system for a long time

    *   Round_Robin Scheduling (RR)(è½®è¯¢)

        *   designed for time-sharing systems
        *   each process is assigned a time quantum/slice
        *   If the process uses CPU for less than one time quantum, it will release the CPU voluntarily (ä¸»åŠ¨é€€å‡º)
        *   when one time quantum is up , that process is preempted by the scheduler and moved to the tail of the list
        *   Typically, higher average time than SJF, better response time
        *   time quantum is too large â†’ FCFS
        *   time quantum is to small â†’ processor sharing (å¹¶å‘)
            *   *shorter time quantum means more context switches*
        *   in general, 80% of the CPU bursts should be shorter than the time quantum
        *   

    *   Multilevel Queue Scheduling (å¤šçº§é˜Ÿåˆ—)

        *   partitioned into separate queues

            *   foreground (interactive)
            *   background (batch)

        *   Each process is assigned permanently to one queue based on some properties of the process

        *   Each queue has its own scheduling algorithm

            *   foreground -  RR

            *   background -FCFS

                ![](/review/OS/1555906275098.png)

            ![](OS/1555906275098.png)

            *   Scheduling must be done between the queues
                *   Fixed priority scheduling (possibility of starvation)
                *   Time slice
                    *   each queue gets a certain amount of CPU time which it can schedule amongst its processes

    *   Multilevel Feedback Queue Scheduling

        *   allows process to move between queues

        *   aging can be implemented this way

        *   If a process use more/less CPU time, it is moved to a queue of lower/higher priority â†’ I/O/CPU-bound process will be in higher/lower priority queues

        *   exp

            ![](/review/OS/1555907839535.png)

            ![](OS/1555907839535.png)

        -   number of queues
        -   scheduling algorithms for each queue
        -   method used to determine when to upgrade a process
        -   method used to determine when to demote a process
        -   method used to determine which queue a process will enter when that process needs service

*   Multiple-Processor Scheduling

    *   Homogeneous(åŒæ„) processors
    *   Load balancing
        *   push migration
        *   pull migration
    *   Asymmetric multiprocessing (éå¹³è¡¡å¤„ç†)
        *   only on processor accesses the system data
            *   alleviating(é™ä½) the need for data shring
    *   Symmetric multiprocessing (SMP)
        *   two processors do **not** choose the same process
    *   Processor Affinity (ä¾µæ ¸)
        *   most SMP systems **try** to avoid migration of processes from one processor to  another
            *   Soft/Hard Affinity (æ‰§è¡Œè¿‡ç¨‹ä¸­å¯ä»¥/ä¸å¯ä»¥ä¾µæ ¸)

*   Real-Time Scheduling

    *   Hard real-time systems
    *   the scheduler either **admits** a process and guarantees that the process will complete on-time, or **reject** the request (resource reservation)
    *   secondary storage and virtual memory will cause unavoidable delay
    *   Hard real-time systems usually have special software on special hardware

*   Soft real-time systems

    *   easily doable(å¯è¡Œ) within a general system
    *   may cause unfair resource allocation and longer delay(starvation) for noncritical tasks.
    *   the CPU scheduler must **prevent aging** to occur(critical tasks may have lower priority)
    *   **The dispatch latency must be small**

*   Priority Inversion

    *   a high-priority process needs to access the data that is currently being accessed by a low-priority process â†’ The high-priority process is blocked by the low-priority process
    *   priority-inheritance protocol

*   Thread Scheduling

    *   User-level threads
        *   thread library
    *   Kernel-level threads
        *   scheduled by OS
    *   user-level threads must ultimately be mapped to an associated kernel-level thread
    *   Local scheduling â†’ User-level Thread
    	*   Process-contention Scope (PCS)
    *   Global Scheduling â†’ Kernel-level Thread
    	*   System-contention Scope (SCS)
    
*   Algorithm Evaluation

	*   Deterministic modeling (Analytic evaluation) ç¡®å®šæƒ…å†µä¸‹ çš„æƒ…å½¢è¯æ˜

	*   Queueing models é˜Ÿåˆ—æ¨¡å‹

	*   Simulations ä»¿çœŸ

	*   Implementation è¯æ˜

		<small>ä»ä¸Šå¾€ä¸‹è¯æ˜åŠ›è¶Šå¼ºï¼Œè¶Šéš¾è¯æ˜</small>

*   Operating System 

	*   Scheduling threads using **preemptive** and **priority-based** scheduling algorithms (Real time, system, time sharing, interactive)
	*   The default scheduling class for a process is time sharing (multilevel feedback queue)

# Chapter 6 Process Synchronization

- Bounded-buffer

	``` c++
	//Shared data
	#define BUFFER_SIZE 10
	typedef struct
	{
	    //...
	} item;
	item buffer[BUFFER_SIZE];
	int in = 0;
	int out = 0;
	int counter = 0;
	
	//Producer process
	item nextProduced;
	while(1)
	{
	    while(counter == BUFFER_SIZE);
	    	//do nothing
	    buffer[in] = nextProduced;
	    in = (in + 1) % BUFFER_SIZE;
	    counter++;    
	}
	
	//Consumer process
	item nextConsumed;
	while(1)
	{
	    while(counter == 0)
	        //do nothing
	    nextConsumed = buffer[out];
	    out = (out + 1) % BUFFER_SIZE;
	    counter--;
	}
	```

- **Atomic operation**

	- counter++
	- counterâ€” 

- Race condition

	- two or more processes/thread access and manipulate the same data concurrently
	- the outcome of the execution depends on the particular order in which the access takes place
	- To prevent race conditions, concurrent processes must be synchronized

- The Critical-Section Problem

	- Each process has a code segment, called critical section

	- **Problem**: ensure that when one process is executing in its critical section, no other process is allowed to execute in its critical section

	- The critical-section problem is to design a protocol that processes can use to cooperate

		â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”

		|    entry section      |

		â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤

		|    critical section    |

		â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤

		|       exit section      |

		â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤

		|remainder section |

		â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

		**critical section must run in a mutually exclusive way.**

- Solution to Critical-Section Problem

	- Mutual Exclusion (äº’æ–¥ã€å¿™ç­‰) â†’ é˜²æ­¢å†²çª
	- Progress (ç©ºé—²è®©è¿›) â†’ è¿›å±•æ€§
	- Bounded Waiting (æœ‰é™ç­‰å¾…) â†’ è¿›å±•æ€§
		- <small>é˜²æ­¢é¥¥é¥¿ï¼Œè®©æƒç­‰å¾…ï¼Œå¤šCPUï¼šæ­»é”</small>
	- **the solution cannot depend on relative speed of processes and scheduling policy**
	- Mutual Exclusion

- Bakery Algorithm

	``` c++
	//shared data
	boolean choosing[n];	//false
	int number[n];			//0
	do
	{
	    choosing[i] = true;
	    number[i] = max(number[0],number[1],...,number[n-1])+1;
	    choosing[i] = false;
	    for(j = 0; j < n; ++j)
	    {
	        while(choosing[j]);
	        while((number[j] != 0)&&((number[j],j)<(number[i],i)));
	    }
	    //critical section
	    number[i] = 0;
	    //remainder section
	}while(1)
	```

- Interrupt Disabling

	- disable interrupts â†’ critical section â†’ enable interrupts
	- When interrupts are disabled, no context switch will occur in a critical section
	- Infeasible in a multiprocessor system because all CPUs must be informed
	- Some feature that depend on interrupts (e.g. clock) may not work properly

- Mutual Exclusion (äº’æ–¥é”)

	- TestAndSet

		``` c++
		boolean TestAndSet(boolean &target)
		{
			booean rv = &target;
		    &target = true;
		    return rv;
		}
		```

		``` c++
		//shared data
		boolean lock = false;
		//Process P
		do
		{
		    while(TestAndSet(lock));
		    //critical section
		    lock = false;
		    //remainder section
		}
		```

- Swap

	- **atomically** swap two variables

		``` c++
		void Swap(boolean &a,boolean &b)
		{
		    boolean temp = &a;
		    &a = &b;
		    &b = temp;
		}
		```

		``` C++
		//Global shared data
		boolean lock;	//false
		//Local variable for each process
		boolean key;
		Process Pi
		do
		{
			key = true;
			while(key == true)
		    {
		    	Swap(lock,key);
		    }
		    //critical section
		    lock = false;
		    //remainder section
		}
		```

- Semaphores

	``` c++
	wait(S)
	{
		while(S <= 0);
			--S;
	}
	
	signal(S)
	{
	    ++S:
	}
	```

	- Count semaphore
	- Binary semaphore (mutex locks)

- busy waiting (Spinlock)

- block itself (é˜»å¡æ–¹æ³•ï¼Œä½¿ç”¨PCBå”¤é†’)

	- Define a semaphore as a record

		```
		typedef struct
		{
		    int value;
		    struct process *L;	//waiting queue
		}semaphore;
		```

		- block()
		- wakeup(P)

		``` c++
		wait(S)
		{
		    S.value--;
		    if (s.value < 0)
		    {
		        //add this process to S.L;
		        block();
		    }
		}
		signal(S)
		{
			S.value++;
		    if(S.value <= 0)
		    {
		        //remove a process P from S.L;
		        wakeup(P);
		    }
		}
		```

		

		- if the semaphore is negative, its magnitude is the number of process waiting on that semaphore
		- Busy waiting has not been **completely** eliminated
		- furthermore, we have limited busy waiting to the critical sections of the wait() and signal() operations

- Deadlock and Starvation

	<small>ä¸´ç•Œèµ„æºã€åŒæ­¥å…³ç³»</small>

	- Bounded-Buffer Problem

		``` C++
		//Shared data
		Semaphore full = 0,empty = n,mutex = 1;
		do	//Producer
		{
		    //produce an item in nextP
		    wait(empty);
		    wait(mutex);
		    //add nextP to buffer
		    signal(mutex);
		    signal(full);
		}while(1);
		
		do	//Consumer
		{
		    wait(full);
		    wait(mutex);
		    //remove an item from buffer to nextC
		    signal(mutex);
		    signal(empty);
		    //consume the item in nextC
		}while(1);
		```

	- Readers and Writers Problem

		- Reader first
		- Writer first

		``` C++
		//Shared data
		int readcount;
		semaphore wrt = 1,mutex = 1;
		int readcount = 0;
		do
		{
		    wait(wrt);
		    //writing
		    signal(wrt);
		}while(1);
		do		//Error: å†™è€…é¥¥é¥¿é—®é¢˜
		{
		    wait(mutex);
		    readcount++;
		    if(readcount == 1)
		        wait(wrt);
		    signal(mutex);
		    //reading
		    wait(mutex);
		    readcount--;
		    if(readcount == 0)
		        signal(wrt);
		    signal(mutex);
		}
		```

	- Dining-Philosophers Problem

	- è¿‡ç‹¬æœ¨æ¡¥é—®é¢˜

		``` 
		//Shared data
		int countA = 0;	//Aæ–¹å‘ä¸Šå·²åœ¨ç‹¬æœ¨æ¡¥ä¸Šçš„è¡Œäººæ•°ç›®
		int countB = 0;	//Bæ–¹å‘ä¸Šå·²åœ¨ç‹¬æœ¨æ¡¥ä¸Šçš„æ–°äººæ•°ç›®
		semaphore MA = 1;	//countAçš„äº’æ–¥é”
		semaphore MB = 1;	//countBçš„äº’æ–¥é”
		semaphore mutex = 1;	//å®ç°äº’æ–¥ä½¿ç”¨
		```

		- Aæ–¹å‘è¿‡æ¡¥

			``` C++
			do
			{
			    wait(MA);
			    countA++;
			    if (count == 1)
			    {
			        wait(mutex);
			    }
			    signal(MA);
			    //è¿‡æ¡¥
			    wait(MA);
			    countA--;
			    if(countA == 0)
			    {
			        signal(mutex);
			    }
			    signal(MA);
			}while(1);
			```

- Monitors (ç®¡ç¨‹)

	- High-level synchronization construct that allows the safe sharing of an abstract data type among concurrent processes

		``` C++
		monitor monitor-name
		{
			shared variable declarations
			proceudre body P1()
		    {
		    	//...
		    }
		    	proceudre body P2()
		    {
		    	//...
		    }
		    //...
		    {//initialization code}
		}
		```

	- no more than one process can be executing within a monitor

	- when a process calls a monitor procedure and the monitor has a process running, the caller will be blocked outside the monitor

	- Mutual exclusion is guaranteed with in a monitor

		![](/review/OS/1555948188580.png)

		![](OS/1555948188580.png)

- Condition variables

	- x,y

		- x.wait() means that the process invoking this operation is suspended until another process invokes x.signal();
		- x.signal() operation resumes exactly one suspended process. If no process is suspended, the signal() operation has no effect

		![](/review/OS/1555948399247.png)

		![](OS/1555948399247.png)

		
		
		
		
		|                          Semaphores                          |                     Condition Variables                      |
		| :----------------------------------------------------------: | :----------------------------------------------------------: |
|          Can be used anywhere, but not in a monitor          |                 Can only be used in monitors                 |
		|         wait() does **not** always block its caller          |             wait() **always** blocks its caller              |
		| signal() either releases a process, or increase the semaphore counter | signal() either releases a process ,or the signal is **lost** as if it never occurs |
		| If signal() release a process, the caller and the release **both** continue | If signal() release a process, either the caller or the released continues, but **not** both |
		
		
		
		-  ç®¡ç¨‹æ˜¯å…¬ç”¨æ•°æ®ç»“æ„ï¼Œè¿›ç¨‹æ˜¯ç§æœ‰æ•°æ®ç»“æ„
		- ç®¡ç¨‹é›†ä¸­ç®¡ç†å…±äº«å˜é‡ä¸Šçš„åŒæ­¥æ“ä½œï¼Œä¸´ç•ŒåŒºåˆ†æ•£åœ¨æ¯ä¸ªè¿›ç¨‹ä¸­
		- ç®¡ç¨‹ç®¡ç†å…±äº«èµ„æºï¼Œè¿›ç¨‹å ç”¨ç³»ç»Ÿèµ„æºå’Œå®ç°ç³»ç»Ÿå¹¶å‘æ€§
		- ç®¡ç¨‹è¢«æ¬²ä½¿ç”¨çš„å…±äº«èµ„æºçš„è¿›ç¨‹è°ƒç”¨ï¼Œç®¡ç¨‹å’Œè°ƒç”¨å®ƒçš„è¿›ç¨‹ä¸èƒ½å¹¶å‘å·¥ä½œï¼Œè¿›ç¨‹ä¹‹é—´èƒ½å¹¶å‘å·¥ä½œ
		- ç®¡ç¨‹æ˜¯è¯­è¨€æˆ–æ“ä½œç³»ç»Ÿçš„æˆåˆ†ï¼Œä¸å¿…åˆ›å»ºæˆ–æ’¤é”€ï¼Œè¿›ç¨‹æœ‰ç”Ÿå‘½å‘¨æœŸï¼Œæœ‰åˆ›å»ºæœ‰æ¶ˆäº¡

---

ğŸš§ä¸­æœŸéƒ¨åˆ†æ–½å·¥å®Œæˆï¼ŒæœŸæœ«å†è§(ï½ï¹ƒï½)~zZè¡¥è§‰å»äº†â€¦â€¦ğŸš§





â€‹		

